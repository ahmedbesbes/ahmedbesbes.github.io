<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ahmed BESBES - Data Science Portfolio - AutoML</title><link href="https://ahmedbesbes.com/" rel="alternate"></link><link href="https://ahmedbesbes.com/feeds/automl.atom.xml" rel="self"></link><id>https://ahmedbesbes.com/</id><updated>2019-10-08T18:31:00+02:00</updated><subtitle>Data scientist in the making</subtitle><entry><title>Introduction to AutoML with MLBox</title><link href="https://ahmedbesbes.com/introduction-to-automl-with-mlbox.html" rel="alternate"></link><published>2019-10-08T18:31:00+02:00</published><updated>2019-10-08T18:31:00+02:00</updated><author><name>Axel de Romblay</name></author><id>tag:ahmedbesbes.com,2019-10-08:/introduction-to-automl-with-mlbox.html</id><summary type="html">&lt;p&gt;Today's post is very special. It's written in collaboration with &lt;a href="https://www.linkedin.com/in/axel-de-romblay-6444a990/"&gt;Axel de Romblay&lt;/a&gt; the author of the MLBox Auto-ML package that has gained a lot of popularity these last years. &lt;br&gt; If you haven't heard about this library, go and check it out on &lt;a href="https://github.com/AxeldeRomblay/MLBox"&gt;github&lt;/a&gt;: It encompasses interesting features, it's gaining in maturity and is now under active development. &lt;br&gt;  In this post, we'll show you how you can easily use it to train an automated machine learning pipeline for a classification problem. It'll start off by loading and cleaning the data, removing drift, launching a strong pipeline of accelerated optimization and generating predictions.&lt;img src="./images/article_10/stars.png"&gt; &lt;img src="./images/article_10/mlbox.png"&gt;&lt;/p&gt;</summary><content type="html">&lt;/head&gt;&lt;body&gt;&lt;p&gt;
&lt;/p&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Today's post is very special. It's written in collaboration with &lt;a href="https://www.linkedin.com/in/axel-de-romblay-6444a990/"&gt;Axel de Romblay&lt;/a&gt; the author of the MLBox Auto-ML package that has gained a lot of popularity these last years.&lt;/p&gt;
&lt;p&gt;If you haven't heard about this library, go and check it out on &lt;a href="https://github.com/AxeldeRomblay/MLBox"&gt;github&lt;/a&gt;: It encompasses interesting features, it's gaining in maturity and is now under active development.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/article_10/stars.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/article_10/mlbox.png"/&gt;&lt;/p&gt;
&lt;p&gt;In this post, we'll show you how you can easily use it to train an automated machine learning pipeline for a classification problem. It'll start off by loading and cleaning the data, removing drift, launching a strong pipeline of accelerated optimization and generating predictions.&lt;/p&gt;
&lt;h1 id="0---Introduction-to-Auto-ML"&gt;0 - Introduction to Auto-ML&lt;a class="anchor-link" href="#0---Introduction-to-Auto-ML"&gt;¶&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;MLBox has been presented to many machine learning Meetups. You can check one of the slides here. It's a good start to have an overview of the library of more generally of the AutoML concept.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
 

&lt;p&gt;&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="485" marginheight="0" marginwidth="0" scrolling="no" src="//www.slideshare.net/slideshow/embed_code/key/9NqV164Uhv4NZH" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" width="100%"&gt; &lt;/iframe&gt;

&lt;p&gt;&lt;/p&gt;&lt;div style="margin-bottom:5px"&gt; &lt;strong&gt; &lt;a href="//www.slideshare.net/AxeldeRomblay/mlbox-082-178177773" target="_blank" title="MLBox 0.8.2 "&gt;MLBox 0.8.2 &lt;/a&gt; &lt;/strong&gt; de &lt;strong&gt;&lt;a href="//www.slideshare.net/AxeldeRomblay" target="_blank"&gt;Axel de Romblay&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="1---Downloading-the-train-and-test-datasets"&gt;1 - Downloading the train and test datasets&lt;a class="anchor-link" href="#1---Downloading-the-train-and-test-datasets"&gt;¶&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;For the purpose of this notebook, we'll be solving the famous Titanic Kaggle &lt;a href="https://www.kaggle.com/c/titanic/"&gt;challenge&lt;/a&gt; which consists in predicting the survival of passengers based on their attributes (Sex, Age, Name, etc).&lt;/p&gt;
&lt;p&gt;If you're not familiar with this competition you can check this &lt;a href="https://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html"&gt;article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's now download the data:&lt;/p&gt;
&lt;h3 id="From-Kaggle-if-you-have-an-account"&gt;From Kaggle if you have an account&lt;a class="anchor-link" href="#From-Kaggle-if-you-have-an-account"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;If you have a Kaggle account you can generate an API token right here on your profile page:&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/article_10/kaggle-api-key.png" width="75%"/&gt;&lt;/p&gt;
&lt;p&gt;Once the API token is generated, you'll have a kaggle.json downloaded on your system that contains your usename and key.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you're on Unix-based OS, place this file in: ~/.kaggle/ and then&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chmod &lt;span class="m"&gt;600&lt;/span&gt; ~/.kaggle/kaggle.json
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;If you're on a Windows machine:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;KAGGLE_USERNAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;your-username&amp;gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;KAGGLE_KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;your-key&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="From-the-internet:"&gt;From the internet:&lt;a class="anchor-link" href="#From-the-internet:"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Make sure you have wget installed: &lt;code&gt;pip install wget&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;wget&lt;/span&gt;

&lt;span class="n"&gt;train_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&amp;amp;Expires=1570183347&amp;amp;Signature=O7hakdmzfjCnK6so6Yj%2B4TEscq4YD9smNLasKOcBK4k2A737DH3gwcDU5LMZwLH20rjrhrk5vKueJh5EDM8IX5X0l0rDZ4f%2BosbFU&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;Hig5s5MetsPMYDqEZyYRq6BRWd4kazaeHnoEjiDnvmHf2a0eQ9&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;C7A9TX72MwVi50MFyD&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;3MXjE7NX0ciXMc1RQVV5fpr5u1qJ98yBaJZS1CWWyXx5D1Q3U5VfvcIPGds%2B3XIYko9MIbd4wnk2g4K3rJijAyTnjoi1sVhyyms0buyxXNQH4eQ3OdUW6EbB1NzHv9F93ZTMUKoY76hAlKNdpFCE&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;pD8YW22hfHEiifUhipmtA%3D%3D'&lt;/span&gt;
&lt;span class="n"&gt;train_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;test_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&amp;amp;Expires=1570183224&amp;amp;Signature=ppvKN7j%2BdPC5z5G4HARm&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;aLpkBIfF&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;1%2BbFR9Zwcy81aY&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;TPtoKS8ZZDa2RzmcFfa2C4nm7FGLM%2B70cl742KUjWTDXqEWSyYdvIXabP82LRXJ6UGKGixmoGLcAaNhKT&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;CQrmYmhcrrUoy%2BFj6Ik%2BHtg9vWKaAG6zZAGP3l1uCRQSMrThKBkV6nO1cpeJ&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;8JoeB2DBNdjL&lt;/span&gt;&lt;span class="si"&gt;%2F&lt;/span&gt;&lt;span class="s1"&gt;noT7kj2LS2U1pyZjhD3HeIwpBCkbZ6Cdt%2BrXT10YYkrc7tk%2BWHIsIwINg4oC681YGwL99N0IQAkNbxffx4cU7tWwZAHZ6JIdJzohsN8b6QifAMnV5oqc21ad32I5LAz5g9p9PlSgLCzmw%3D%3D'&lt;/span&gt;
&lt;span class="n"&gt;test_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wget&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then place train.csv and test.csv in &lt;code&gt;data&lt;/code&gt; folder at the root of the project.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="2---Environment-setup-and-installing-MLBox-from-PyPI"&gt;2 - Environment setup and installing MLBox from PyPI&lt;a class="anchor-link" href="#2---Environment-setup-and-installing-MLBox-from-PyPI"&gt;¶&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Creating a conda virtual environment is recommended because MLBox encompasses several dependencies that might mess with your current libraries. Having a clean virtual environment is the right solution and if anything goes wrong you can remove it without impacting your system.&lt;/p&gt;
&lt;p&gt;You can create it using conda or pyenv. I'm a conda user so I'll use conda.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda create -n automl &lt;span class="nv"&gt;python&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.7
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This creates an environment named &lt;strong&gt;automl&lt;/strong&gt; that has python 3.7 preconfigured on it.&lt;/p&gt;
&lt;p&gt;If you're on OSX like me, you'll have to install &lt;strong&gt;OpenMP&lt;/strong&gt; (Open Multi-Processing), an efficient implementation of multithreading, via brew:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;base&lt;span class="o"&gt;)&lt;/span&gt; brew install libomp
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now activate automl and install MLBox directly form PyPI:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;base&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nb"&gt;source&lt;/span&gt; activate mlbox
&lt;span class="o"&gt;(&lt;/span&gt;automl&lt;span class="o"&gt;)&lt;/span&gt; pip install mlbox
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="./images/article_10/dependencies.png"/&gt;&lt;/p&gt;
&lt;p&gt;As you see, mlbox has quite a lot of dependencies such as scikit-learn, pandas, etc. That's why we created an empty virtual environment.&lt;/p&gt;
&lt;h3 id="[Optional]-:-accessing-the-automl-kernel-from-Jupyter."&gt;[Optional] : accessing the automl kernel from Jupyter.&lt;a class="anchor-link" href="#[Optional]-:-accessing-the-automl-kernel-from-Jupyter."&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;If you'd like to use jupyter notebook on this environment without activating it but by selecting the kernel only from the base jupyter dropdown list; you'll have to install &lt;strong&gt;ipykernel&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;automl&lt;span class="o"&gt;)&lt;/span&gt; conda install ipykernel
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src="./images/article_10/ipykernel.png" width="50%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now you're good to go!&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="3---Testing-MLBox:-from-data-ingestion-to-model-building"&gt;3 - Testing MLBox: from data ingestion to model building&lt;a class="anchor-link" href="#3---Testing-MLBox:-from-data-ingestion-to-model-building"&gt;¶&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now we're going to test and run MLBox to quickly build a model to solve the Kaggle Titanic Challenge.&lt;/p&gt;
&lt;p&gt;For more information about the documentation of the package and the API you can visit the following links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The official repository: &lt;a href="https://github.com/AxeldeRomblay/MLBox"&gt;https://github.com/AxeldeRomblay/MLBox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The official documentation: &lt;a href="https://mlbox.readthedocs.io/en/latest/"&gt;https://mlbox.readthedocs.io/en/latest/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Importing-MLBox"&gt;Importing MLBox&lt;a class="anchor-link" href="#Importing-MLBox"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;

from IPython.core.display import display, HTML
display(HTML('&amp;lt;style&amp;gt;.prompt{width: 0px; min-width: 0px; visibility: collapse}&amp;lt;/style&amp;gt;'))

import warnings
warnings.filterwarnings("ignore")

from mlbox.preprocessing.reader import Reader
from mlbox.preprocessing.drift_thresholder import Drift_thresholder
from mlbox.optimisation.optimiser import Optimiser 
from mlbox.prediction.predictor import Predictor
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;



&lt;div class="output_html rendered_html output_subarea"&gt;
&lt;style&gt;.prompt{width: 0px; min-width: 0px; visibility: collapse}&lt;/style&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stderr output_text"&gt;
&lt;pre&gt;Using TensorFlow backend.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;CPU times: user 2.9 s, sys: 1.29 s, total: 4.18 s
Wall time: 10.3 s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Inputs-to-MLBox"&gt;Inputs to MLBox&lt;a class="anchor-link" href="#Inputs-to-MLBox"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;If you're having a train and a test set like in any Kaggle competition, you can feed these two paths directly to MLBox as well as the target name.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;paths&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"./data/train.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"./data/test.csv"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 
&lt;span class="n"&gt;target_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Survived"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Reading-and-preprocessing"&gt;Reading and preprocessing&lt;a class="anchor-link" href="#Reading-and-preprocessing"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The Reader class of MLBox is in charge of preparing the data.&lt;/p&gt;
&lt;p&gt;It basically provides methods and utilities to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read in the data with the correct separator (csv, xls, json, and h5) and load it&lt;/li&gt;
&lt;li&gt;Clean the data by: &lt;ul&gt;
&lt;li&gt;deleting Unnamed columns&lt;/li&gt;
&lt;li&gt;inferring column types (float, int, list)&lt;/li&gt;
&lt;li&gt;processing dates and extracting relevant information from it: year, month, day, day_of_week, hour, etc.&lt;/li&gt;
&lt;li&gt;removing duplicates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prepare train and test splits&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More information here: &lt;a href="https://mlbox.readthedocs.io/en/latest/features.html#mlbox.preprocessing.Reader"&gt;https://mlbox.readthedocs.io/en/latest/features.html#mlbox.preprocessing.Reader&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [3]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;rd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Reader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;","&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;reading csv : train.csv ...
cleaning data ...
CPU time: 7.071681022644043 seconds

reading csv : test.csv ...
cleaning data ...
CPU time: 0.03354978561401367 seconds

&amp;gt; Number of common features : 11

gathering and crunching for train and test datasets ...
reindexing for train and test datasets ...
dropping training duplicates ...
dropping constant variables on training set ...

&amp;gt; Number of categorical features: 5
&amp;gt; Number of numerical features: 6
&amp;gt; Number of training samples : 891
&amp;gt; Number of test samples : 418

&amp;gt; Top sparse features (% missing values on train set):
Cabin       77.1
Age         19.9
Embarked     0.2
dtype: float64

&amp;gt; Task : classification
0.0    549
1.0    342
Name: Survived, dtype: int64

encoding target ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;When this function is done running, it creates a folder named &lt;code&gt;save&lt;/code&gt; where it dumps the target encoder for later use.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [4]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"train"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[4]:&lt;/div&gt;



&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Age&lt;/th&gt;
      &lt;th&gt;Cabin&lt;/th&gt;
      &lt;th&gt;Embarked&lt;/th&gt;
      &lt;th&gt;Fare&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Parch&lt;/th&gt;
      &lt;th&gt;PassengerId&lt;/th&gt;
      &lt;th&gt;Pclass&lt;/th&gt;
      &lt;th&gt;Sex&lt;/th&gt;
      &lt;th&gt;SibSp&lt;/th&gt;
      &lt;th&gt;Ticket&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;22.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;7.2500&lt;/td&gt;
      &lt;td&gt;Braund, Mr. Owen Harris&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;A/5 21171&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;C85&lt;/td&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;71.2833&lt;/td&gt;
      &lt;td&gt;Cumings, Mrs. John Bradley (Florence Briggs Th...&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;PC 17599&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;26.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;7.9250&lt;/td&gt;
      &lt;td&gt;Heikkinen, Miss. Laina&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;STON/O2. 3101282&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;35.0&lt;/td&gt;
      &lt;td&gt;C123&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;53.1000&lt;/td&gt;
      &lt;td&gt;Futrelle, Mrs. Jacques Heath (Lily May Peel)&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;113803&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;35.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;8.0500&lt;/td&gt;
      &lt;td&gt;Allen, Mr. William Henry&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;373450&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Removing-drift"&gt;Removing drift&lt;a class="anchor-link" href="#Removing-drift"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is an innovative feature I haven't encountered in other packages. The main idea is to automatically detect and remove variables that have a distribution that is substantially different between the train and the test set.&lt;/p&gt;
&lt;p&gt;This happens quite a lot and we generally talk about biased data. You could have for example a situation when the  train set has a population of young people whereas the test has elderly only. This indicates that the age feature is not robust and may lead to a poor performance of the model when testing. So it has to be discarded.&lt;/p&gt;
&lt;p&gt;More information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;about the algorithm: &lt;a href="https://github.com/AxeldeRomblay/MLBox/blob/master/docs/webinars/features.pdf"&gt;https://github.com/AxeldeRomblay/MLBox/blob/master/docs/webinars/features.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;about MLBox implementation: &lt;a href="https://mlbox.readthedocs.io/en/latest/features.html#mlbox.preprocessing.Drift_thresholder"&gt;https://mlbox.readthedocs.io/en/latest/features.html#mlbox.preprocessing.Drift_thresholder&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;img src="./images/article_10/drift.png" width="75%"/&gt;
&lt;figcaption style="text-align:center"&gt;Diagram taken from &lt;a href="https://github.com/AxeldeRomblay/MLBox/blob/master/docs/webinars/features.pdf"&gt;this presentation&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-does-MLBox-compute-drifts-for-individual-variables"&gt;How does MLBox compute drifts for individual variables&lt;a class="anchor-link" href="#How-does-MLBox-compute-drifts-for-individual-variables"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;MLBox builds a classifier that separates train from test data. It then uses the ROC score related to this classifier as a measure of the drift.&lt;/p&gt;
&lt;p&gt;This makes sense:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the drift score is high (i.e. the ROC score is high) the ability the discern train data from test data is easy, which means that the two distributions are very different.&lt;/li&gt;
&lt;li&gt;Otherwise, if the drift score is low (i.e. the ROC score is low) the classifier is not able to separate the two disctributions correctly.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MLBox provides a class called Drift_thresholder that takes as input the train and test sets as well as the target and computes a drift score of each one of the variables.&lt;/p&gt;
&lt;p&gt;Drift_thresholder then deletes the variables that have a drift score higher that a threshold (default to 0.6).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [5]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dft&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Drift_thresholder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dft&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;computing drifts ...
CPU time: 0.2802262306213379 seconds

&amp;gt; Top 10 drifts

('PassengerId', 0.9977578475336322)
('Name', 0.9884762572435108)
('Ticket', 0.6689163729323582)
('Cabin', 0.17240596303347422)
('Embarked', 0.07433353190182412)
('Sex', 0.03134833148225069)
('Pclass', 0.02615537570548665)
('SibSp', 0.02514716046656451)
('Age', 0.02111933805574351)
('Parch', 0.020186881798871514)

&amp;gt; Deleted variables : ['Name', 'PassengerId', 'Ticket']
&amp;gt; Drift coefficients dumped into directory : save
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As you see here, &lt;code&gt;Name&lt;/code&gt;, &lt;code&gt;PassengerId&lt;/code&gt; and &lt;code&gt;Ticket&lt;/code&gt; get removed beacause of their respective drift scores. If you think about it, this is not surprising at all because these variables, given their nature, can have any random value thus resulting in plausible drift between their train and test distributions.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-heavy-lifting-:-optimizing"&gt;The heavy lifting : optimizing&lt;a class="anchor-link" href="#The-heavy-lifting-:-optimizing"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This section performs the optimisation of the pipeline and tries different configurations of the parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NA encoder (missing values encoder)&lt;/li&gt;
&lt;li&gt;CA encoder (categorical features encoder)&lt;/li&gt;
&lt;li&gt;Feature selector (OPTIONAL)&lt;/li&gt;
&lt;li&gt;Stacking estimator - feature engineer (OPTIONAL)&lt;/li&gt;
&lt;li&gt;Estimator (classifier or regressor)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details here: &lt;a href="https://mlbox.readthedocs.io/en/latest/features.html#mlbox.optimisation.Optimiser"&gt;https://mlbox.readthedocs.io/en/latest/features.html#mlbox.optimisation.Optimiser&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We first instantiate the Optimiser class:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [6]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;opt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Optimiser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Then we can run it using the default model configuration set as default (LightGBM) without any autoML or complex grid search.&lt;/p&gt;
&lt;p&gt;This should be the first baseline&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [7]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;warnings&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filterwarnings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'ignore'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ne"&gt;DeprecationWarning&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;opt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# evaluation of default configuration&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;No parameters set. Default configuration is tested

##################################################### testing hyper-parameters... #####################################################

&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}

&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}

&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}


MEAN SCORE : neg_log_loss = -0.6324717748298669
VARIANCE : 0.003224557409561235 (fold 1 = -0.6356963322394281, fold 2 = -0.6292472174203056)
CPU time: 0.3516390323638916 seconds

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The neg_log_loss = -0.6325 as a first baseline.&lt;/p&gt;
&lt;p&gt;Let's now define a space of multiple configurations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ne__numerical_strategy: how to handle missing data in numerical features&lt;/li&gt;
&lt;li&gt;ce__strategy: how to handle categorical variables encoding&lt;/li&gt;
&lt;li&gt;fs: feature selection&lt;/li&gt;
&lt;li&gt;stck: meta-features stacker&lt;/li&gt;
&lt;li&gt;est: final estimator&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [8]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;space&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;'ne__numerical_strategy'&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s2"&gt;"search"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"choice"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="s2"&gt;"space"&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"mean"&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt;
        &lt;span class="s1"&gt;'ce__strategy'&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s2"&gt;"search"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"choice"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="s2"&gt;"space"&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="s2"&gt;"label_encoding"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"random_projection"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"entity_embedding"&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt; 
        &lt;span class="s1"&gt;'fs__threshold'&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s2"&gt;"search"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"uniform"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="s2"&gt;"space"&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt; 
        &lt;span class="s1"&gt;'est__strategy'&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s2"&gt;"search"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"choice"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                         &lt;span class="s2"&gt;"space"&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="s2"&gt;"RandomForest"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"ExtraTrees"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"LightGBM"&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt;
        &lt;span class="s1"&gt;'est__max_depth'&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;&lt;span class="s2"&gt;"search"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"choice"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                          &lt;span class="s2"&gt;"space"&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;opt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# computation of the optimal parameters configuration&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}      
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.08687679026044265}
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 13, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.46568318951415477    
VARIANCE : 0.026560479820748356 (fold 1 = -0.49224366933490316, fold 2 = -0.43912270969340644)
CPU time: 1.261826992034912 seconds                 
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                                
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1880309314413372}     
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 13, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -0.6319877461453932                               
VARIANCE : 0.00828355918984891 (fold 1 = -0.6402713053352421, fold 2 = -0.6237041869555443)
CPU time: 0.3333399295806885 seconds                                          
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}   
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                                
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.0990794719864227}     
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 8, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.4454291007965345                               
VARIANCE : 0.019103462344236627 (fold 1 = -0.4645325631407711, fold 2 = -0.4263256384522979)
CPU time: 1.1755399703979492 seconds                                          
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'entity_embedding'}                             
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.06957009042046701}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 8, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.4736455217220734                              
VARIANCE : 0.02977300361691196 (fold 1 = -0.5034185253389853, fold 2 = -0.44387251810516143)
CPU time: 1.1559529304504395 seconds                                         
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}  
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                               
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1136890222014426}    
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 13, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.49441034337999                                
VARIANCE : 0.03075404911142718 (fold 1 = -0.5251643924914172, fold 2 = -0.46365629426856286)
CPU time: 1.1168630123138428 seconds                                         
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                               
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.14587669858515695}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 8, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.4360647044652233                              
VARIANCE : 0.014420298515524094 (fold 1 = -0.4504850029807474, fold 2 = -0.4216444059496992)
CPU time: 1.1984360218048096 seconds                                         
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                               
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.01947150829296879}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 11, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.4473474648918937                              
VARIANCE : 0.020381112005992352 (fold 1 = -0.46772857689788605, fold 2 = -0.42696635288590135)
CPU time: 1.133007287979126 seconds                                          
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}  
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'random_projection'}                            
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.17253154079302718}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 13, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -0.6613447322655455                              
VARIANCE : 0.0076144189526844985 (fold 1 = -0.6537303133128609, fold 2 = -0.6689591512182299)
CPU time: 0.3399369716644287 seconds                                         
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}  
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'entity_embedding'}                             
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.06486503755165093}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 13, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -1.0153248545196272                              
VARIANCE : 0.23084687444268726 (fold 1 = -1.2461717289623144, fold 2 = -0.7844779800769399)
CPU time: 0.5311071872711182 seconds                                         
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}  
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'entity_embedding'}                             
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18047475027201043}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 10, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -1.019618258856772                               
VARIANCE : 0.2219659123625779 (fold 1 = -1.2415841712193498, fold 2 = -0.797652346494194)
CPU time: 0.5522429943084717 seconds                                         
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                                
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.11173101739685073}    
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 8, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -0.6131877515974304                               
VARIANCE : 0.0037047599486706995 (fold 1 = -0.6168925115461011, fold 2 = -0.6094829916487597)
CPU time: 0.3417699337005615 seconds                                          
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}   
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'entity_embedding'}                              
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.049226083069767175}   
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 9, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -1.0014180338207277                               
VARIANCE : 0.22734321093705623 (fold 1 = -1.228761244757784, fold 2 = -0.7740748228836716)
CPU time: 0.4224519729614258 seconds                                          
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}   
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}                                
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.07403572702748741}    
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 13, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -0.6546289643107069                               
VARIANCE : 0.023783736990201865 (fold 1 = -0.6784127013009088, fold 2 = -0.6308452273205051)
CPU time: 0.5296919345855713 seconds                                          
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'random_projection'}                             
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.04051608502201576}    
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}
MEAN SCORE : neg_log_loss = -0.45189925322026037                              
VARIANCE : 0.01711748107054034 (fold 1 = -0.4690167342908007, fold 2 = -0.43478177214972)
CPU time: 1.256556749343872 seconds                                           
##################################################### testing hyper-parameters... #####################################################
&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}
&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'random_projection'}                             
&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.10348301173760452}    
&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 13, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}
MEAN SCORE : neg_log_loss = -0.6366110501785736                               
VARIANCE : 0.004125012820492324 (fold 1 = -0.6324860373580813, fold 2 = -0.6407360629990659)
CPU time: 0.4205179214477539 seconds                                          
100%|██████████| 15/15 [00:12&amp;lt;00:00,  1.25it/s, best loss: 0.4360647044652233]


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

{'ce__strategy': 'label_encoding', 'est__max_depth': 8, 'est__strategy': 'ExtraTrees', 'fs__threshold': 0.14587669858515695, 'ne__numerical_strategy': 'mean'}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [9]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;opt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;


&lt;div class="output_area"&gt;

&lt;div class="prompt"&gt;&lt;/div&gt;


&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;##################################################### testing hyper-parameters... #####################################################

&amp;gt;&amp;gt;&amp;gt; NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '&amp;lt;NULL&amp;gt;'}

&amp;gt;&amp;gt;&amp;gt; CA ENCODER :{'strategy': 'label_encoding'}

&amp;gt;&amp;gt;&amp;gt; FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.14587669858515695}

&amp;gt;&amp;gt;&amp;gt; ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 8, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}


MEAN SCORE : neg_log_loss = -0.4360647044652233
VARIANCE : 0.014420298515524094 (fold 1 = -0.4504850029807474, fold 2 = -0.4216444059496992)
CPU time: 1.1531641483306885 seconds

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="output_area"&gt;

&lt;div class="prompt output_prompt"&gt;Out[9]:&lt;/div&gt;




&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;-0.4360647044652233&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Running this pipeline resulted in a higher neg loss, which is better.&lt;/p&gt;
&lt;p&gt;There's clearly very good potential of more improvement if we define a better space of search or stacking operations and maybe other feature selection techniques.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="4---Running-predictions"&gt;4 - Running predictions&lt;a class="anchor-link" href="#4---Running-predictions"&gt;¶&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now we fit the optimal pipeline and predict on our test dataset.&lt;/p&gt;
&lt;p&gt;More details here: &lt;a href="https://mlbox.readthedocs.io/en/latest/features.html#mlbox.prediction.Predictor"&gt;https://mlbox.readthedocs.io/en/latest/features.html#mlbox.prediction.Predictor&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [ ]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class="highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;prd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Predictor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;prd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="5---Conclusion"&gt;5 - Conclusion&lt;a class="anchor-link" href="#5---Conclusion"&gt;¶&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Running an automated AutoML pipeline has never been easier. With MLBox, you can do this very quickly and efficiently so that you can focus on what really matters when solving a business problem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding the problem&lt;/li&gt;
&lt;li&gt;Acquiring and consolidating the right data&lt;/li&gt;
&lt;li&gt;Formalizing the performance metrics to reach and compute&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's hope these three first steps don't get automated soon :)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
 

&lt;p&gt;&lt;/p&gt;</content><category term="MLBox"></category></entry></feed>